{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from reid import datasets, models\n",
    "from reid.utils.data import transforms as T\n",
    "from reid.utils.data.preprocessor import Preprocessor\n",
    "from reid.utils.osutils import set_paths\n",
    "from reid.utils.serialization import load_checkpoint\n",
    "from reid.models.CompactBilinearPooling_dsybaik import CompactBilinearPooling\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(maps):\n",
    "    flattened = np.transpose(maps, (1, 0, 2, 3)).reshape(maps.shape[1], int(maps.size/maps.shape[1]))\n",
    "    return flattened\n",
    "\n",
    "def organize(flattened, num_map, feat_dim, h, w):\n",
    "    maps = flattened.reshape(feat_dim, num_map, h, w)\n",
    "    maps = np.transpose(maps, (1,0,2,3))\n",
    "    return maps\n",
    "\n",
    "def feat_to_color(maps):\n",
    "    num_img, dim_feat, h, w = maps.shape\n",
    "    maps_flatten = flatten(maps)\n",
    "    maps_flatten_reduced = PCA(n_components=3).fit_transform(maps_flatten.transpose())\n",
    "    maps_reduced = organize(maps_flatten_reduced.transpose(), num_img, 3, h, w)\n",
    "    return maps_reduced\n",
    "\n",
    "def normalize_01(m):\n",
    "    max_value = m.max()\n",
    "    min_value = m.min()\n",
    "    r = max_value - min_value\n",
    "    n = (m- min_value) / r \n",
    "    return n\n",
    "\n",
    "def mapwise_normalize(map1, feats):\n",
    "    num_sample, num_channel, h, w = map1.shape\n",
    "#     norms = np.linalg.norm(np.sqrt(np.sum(map1**2, axis=(2,3))), axis=1)\n",
    "    norms = np.sqrt(np.linalg.norm(feats, axis=1))\n",
    "    normalized = map1 / np.reshape(norms, (num_sample, 1,1,1))\n",
    "    return normalized\n",
    "        \n",
    "def visualize_pca_multi(maps_all, feats, num_vis=100, save_id=\"\"):\n",
    "    maps_all_reduced = []\n",
    "    for maps in maps_all[1:]:\n",
    "        maps_all_reduced.append(feat_to_color(mapwise_normalize(maps, feats)))\n",
    "    num_person = maps_all_reduced[0].shape[0]\n",
    "        \n",
    "    for person_idx in range(min(num_person, num_vis)):\n",
    "        fig, ax = plt.subplots(1, len(maps_all))\n",
    "#         fig.set_size_inches((10,10))\n",
    "        for idx, maps_reduced in enumerate([maps_all[0]] + maps_all_reduced):\n",
    "            ax[idx].imshow(normalize_01(np.transpose(maps_reduced[person_idx,::-1,:,:], (1,2,0))))\n",
    "            ax[idx].set_axis_off()\n",
    "        plt.show()\n",
    "#         fig.savefig(savepath.format(save_id, person_idx))\n",
    "\n",
    "def sel_random_target(target):\n",
    "    labels = np.unique([t[1] for t in target])\n",
    "    labels = np.delete(labels, labels==0)\n",
    "    sel_labels = np.random.choice(labels, 200, replace=False)\n",
    "    sel_target = [t for t in target if t[1] in sel_labels]\n",
    "    _, sel_target = map(list, zip(*sorted(zip([t[1] for t in sel_target], sel_target))))\n",
    "    return sel_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Settings \"\"\"\n",
    "exp_dir = \"logs/market1501/d2_b250\"\n",
    "batch_size = 60\n",
    "args = json.load(open(osp.join(exp_dir, \"args.json\"), \"r\"))\n",
    "set_paths('paths')\n",
    "np.random.seed(0)\n",
    "# np.random.seed(int(time.time()))\n",
    "# savepath = 'vis_examples/{}_{}.png'\n",
    "\n",
    "\"\"\" Load dataset \"\"\"\n",
    "dataset = datasets.create(args['dataset'], \"data/{}\".format(args['dataset']))\n",
    "test_transformer = T.Compose([\n",
    "        T.RectScale(args['height'], args['width']),\n",
    "        T.CenterCrop((args['crop_height'], args['crop_width'])),\n",
    "        T.ToTensor(),\n",
    "        T.RGB_to_BGR(),\n",
    "        T.NormalizeBy(255),\n",
    "        ])\n",
    "target = sel_random_target(list(set(dataset.query) | set(dataset.gallery)))\n",
    "test_loader = DataLoader(\n",
    "        Preprocessor(target,\n",
    "                     root=dataset.images_dir, transform=test_transformer),\n",
    "        batch_size=batch_size, num_workers=args['workers'],\n",
    "        shuffle=False, pin_memory=True)\n",
    "\n",
    "\"\"\" Load model \"\"\"\n",
    "model = models.create(args['arch'], features=args['features'], \n",
    "                      dilation=args['dilation'], initialize=False).cuda()\n",
    "model_weight = osp.join(exp_dir, 'epoch_750.pth.tar')\n",
    "checkpoint = load_checkpoint(model_weight)\n",
    "model.app_feat_extractor.load_state_dict(checkpoint['app_state_dict'])\n",
    "model.part_feat_extractor.load_state_dict(checkpoint['part_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\"\"\" Extract feature maps \"\"\"\n",
    "num_test = len(target)\n",
    "feat1, feat2, feat_out, h, w = 512, 128, 512, 20, 10\n",
    "pool = CompactBilinearPooling(feat1, feat2, feat_out, sum_pool=True)\n",
    "\n",
    "app_feats = np.zeros((num_test, feat1, h, w))\n",
    "part_feats = np.zeros((num_test, feat2, h, w))\n",
    "bilinear_feats = np.zeros((num_test, feat_out))\n",
    "target_imgs = np.zeros((num_test, 3, args['crop_height'], args['crop_width']))\n",
    "for i, (imgs, fnames, pids, _) in enumerate(test_loader):\n",
    "    app_feat = model.app_feat_extractor(imgs.cuda())\n",
    "    part_feat = model.part_feat_extractor(imgs.cuda())\n",
    "    bilinear_feat = pool(app_feat, part_feat)\n",
    "    \n",
    "    i_start = i * batch_size\n",
    "    i_end = min((i+1) * batch_size, num_test)\n",
    "    app_feats[i_start:i_end, :,:,:] = app_feat.detach().cpu().numpy().copy()\n",
    "    part_feats[i_start:i_end, :,:,:] = part_feat.detach().cpu().numpy().copy()\n",
    "    bilinear_feats[i_start:i_end,:] = bilinear_feat.detach().cpu().numpy().copy()\n",
    "    target_imgs[i_start:i_end, :,:,:] = imgs.detach().cpu().numpy().copy()\n",
    "\n",
    "\"\"\" Visualize maps \"\"\"\n",
    "num_vis = 200\n",
    "visualize_pca_multi([target_imgs[:num_vis], app_feats[:num_vis], part_feats[:num_vis]], bilinear_feats[:num_vis], num_vis=num_vis, save_id=\"\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
